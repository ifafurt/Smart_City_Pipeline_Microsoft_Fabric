{"cells":[{"cell_type":"code","source":["%run nb_config"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"971d68ec-0984-4a9d-a091-4886b2abd2ee","normalized_state":"finished","queued_time":"2026-01-06T18:48:04.0325306Z","session_start_time":"2026-01-06T18:48:04.0328876Z","execution_start_time":"2026-01-06T18:48:19.9846031Z","execution_finish_time":"2026-01-06T18:48:20.0451336Z","parent_msg_id":"33aded4e-fa49-41ad-bab4-aca1c1153719"},"text/plain":"StatementMeta(, 971d68ec-0984-4a9d-a091-4886b2abd2ee, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["nb_config Loaded\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9f4b6b1b-1bc0-4af9-8325-7e4af793db2a"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.types import *\n","from datetime import datetime, timezone\n","import uuid\n","import traceback"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"971d68ec-0984-4a9d-a091-4886b2abd2ee","normalized_state":"finished","queued_time":"2026-01-06T18:48:04.0703995Z","session_start_time":null,"execution_start_time":"2026-01-06T18:48:20.0468729Z","execution_finish_time":"2026-01-06T18:48:20.4686211Z","parent_msg_id":"f3449f26-64e0-4dfc-aa0d-ef5930424e21"},"text/plain":"StatementMeta(, 971d68ec-0984-4a9d-a091-4886b2abd2ee, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"12949c29-cbbb-4dc8-9e4e-f2ce6116af69"},{"cell_type":"code","source":["spark = SparkSession.builder.getOrCreate()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"971d68ec-0984-4a9d-a091-4886b2abd2ee","normalized_state":"finished","queued_time":"2026-01-06T18:48:04.2971225Z","session_start_time":null,"execution_start_time":"2026-01-06T18:48:20.4706619Z","execution_finish_time":"2026-01-06T18:48:20.8930244Z","parent_msg_id":"85e50c27-d627-4db8-ba71-567417e7e7b4"},"text/plain":"StatementMeta(, 971d68ec-0984-4a9d-a091-4886b2abd2ee, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6cf272bb-5523-4f58-b6b8-2fd2763a5cd5"},{"cell_type":"code","source":["# Log kayıtlarının tutulacağı yer\n","LOG_PATH = f\"{BASE_PATH}/logs\"\n","RUN_ID = str(uuid.uuid4())"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"971d68ec-0984-4a9d-a091-4886b2abd2ee","normalized_state":"finished","queued_time":"2026-01-06T18:48:04.4185421Z","session_start_time":null,"execution_start_time":"2026-01-06T18:48:20.8949846Z","execution_finish_time":"2026-01-06T18:48:21.3765079Z","parent_msg_id":"c758f46c-2014-4e99-a1ae-6b4c63dcf2ea"},"text/plain":"StatementMeta(, 971d68ec-0984-4a9d-a091-4886b2abd2ee, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b0749cee-4e16-4587-9465-8a0702939927"},{"cell_type":"code","source":["def get_timestamp():\n","    return datetime.now(timezone.utc)\n","\n","# Log Şeması\n","log_schema = StructType([\n","    StructField(\"timestamp\", TimestampType(), True),\n","    StructField(\"level\", StringType(), True),\n","    StructField(\"source\", StringType(), True),\n","    StructField(\"process\", StringType(), True),\n","    StructField(\"message\", StringType(), True),\n","    StructField(\"details\", StringType(), True),\n","    StructField(\"run_id\", StringType(), True)\n","])\n","\n","def write_log(level, source, process, message, details=None):\n","    \"\"\"Log verisini Data Lake'e yazar.\"\"\"\n","    try:\n","        log_data = [{\n","            \"timestamp\": get_timestamp(),\n","            \"level\": level,\n","            \"source\": source,\n","            \"process\": process,\n","            \"message\": message,\n","            \"details\": details,\n","            \"run_id\": RUN_ID\n","        }]\n","        \n","        df = spark.createDataFrame(log_data, schema=log_schema)\n","        \n","        # Delta veya Parquet olarak append modunda yaz\n","        # Hata almamak için Delta formatını tercih ediyoruz, yoksa parquet kullanın.\n","        # nb_config içinde FILE_FORMAT yoksa varsayılan parquet'tir.\n","        df.write.mode(\"append\").parquet(LOG_PATH)\n","        \n","        # Konsola da yazdıralım ki anlık görebilesiniz\n","        print(f\"[{level}] {source} - {message}\")\n","        \n","    except Exception as e:\n","        print(f\"Log yazma hatası: {e}\")\n","\n","# --- EKSİK OLAN KISIM: Logger Sınıfı ve get_logger Fonksiyonu ---\n","\n","class LakehouseLogger:\n","    def __init__(self, name):\n","        self.source = name\n","\n","    def info(self, message):\n","        # Process ismi varsayılan olarak 'ETL' atanır, detaylandırılabilir.\n","        write_log(\"INFO\", self.source, \"General\", message)\n","\n","    def warning(self, message):\n","        write_log(\"WARNING\", self.source, \"General\", message)\n","\n","    def error(self, message, error_details=None):\n","        # Eğer string bir detay verildiyse onu kullan, yoksa None\n","        details = str(error_details) if error_details else None\n","        write_log(\"ERROR\", self.source, \"General\", message, details)\n","\n","    def exception(self, message):\n","        # Python'daki son hatayı (traceback) yakalar\n","        details = traceback.format_exc()\n","        write_log(\"ERROR\", self.source, \"Exception\", message, details)\n","\n","def get_logger(name):\n","    \"\"\"Notebooklarda logger nesnesi oluşturmak için çağrılan fonksiyon.\"\"\"\n","    return LakehouseLogger(name)\n","\n","print(\"nb_logging Loaded\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"971d68ec-0984-4a9d-a091-4886b2abd2ee","normalized_state":"finished","queued_time":"2026-01-06T18:48:04.6071993Z","session_start_time":null,"execution_start_time":"2026-01-06T18:48:21.3783063Z","execution_finish_time":"2026-01-06T18:48:21.775997Z","parent_msg_id":"70a943ea-cd13-4850-8557-4e3c98a7f632"},"text/plain":"StatementMeta(, 971d68ec-0984-4a9d-a091-4886b2abd2ee, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["nb_logging Loaded\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"06fbe88d-e444-4981-9764-7fbdf745f644"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"ef76179e-6a37-49a7-8dfd-375bb9aefc28","known_lakehouses":[{"id":"ef76179e-6a37-49a7-8dfd-375bb9aefc28"}],"default_lakehouse_name":"smart_city_lakehouse","default_lakehouse_workspace_id":"39a4a4bf-aa31-41f4-a9b5-28379d4eaba4"}}},"nbformat":4,"nbformat_minor":5}